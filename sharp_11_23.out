  0%|                  | 0/200000 [00:00<?, ?it/s]Namespace(affine=False, batch=14, img_size=128, iter=200000, lr=0.0001, n_bits=5, n_block=4, n_flow=32, n_sample=20, no_lu=False, path='../sharp/', temp=0.7, type='sharp')
/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
  0%|      | 1/200000 [00:05<314:36:23,  5.66s/it]Loss: 2.27643; logP: -2.03258; logdet: 4.75615; lrLoss: 2.27643; logP: -2.03258; logdet: 4.75615; lrLoss: 283.16104; logP: -282.91437; logdet: 4.75334Loss: 283.16104; logP: -282.91437; logdet: 4.75334Loss: 13.63869; logP: -13.38727; logdet: 4.74858; Loss: 13.63869; logP: -13.38727; logdet: 4.74858; Loss: 44.98246; logP: -44.72651; logdet: 4.74404; Loss: 44.98246; logP: -44.72651; logdet: 4.74404; Loss: 27.73746; logP: -27.47653; logdet: 4.73907; Loss: 27.73746; logP: -27.47653; logdet: 4.73907; Loss: 31.27743; logP: -31.01175; logdet: 4.73432; Loss: 31.27743; logP: -31.01175; logdet: 4.73432; Loss: 23.41828; logP: -23.14804; logdet: 4.72976; Loss: 23.41828; logP: -23.14804; logdet: 4.72976; Loss: 20.03843; logP: -19.76385; logdet: 4.72542; Loss: 20.03843; logP: -19.76385; logdet: 4.72542; Loss: 16.27071; logP: -15.99201; logdet: 4.72131; Loss: 16.27071; logP: -15.99201; logdet: 4.72131; Loss: 11.41241; logP: -11.12980; logdet: 4.71739; Loss: 11.41241; logP: -11.12980; logdet: 4.71739; Loss: 8.67376; logP: -8.38746; logdet: 4.71370; lrLoss: 8.67376; logP: -8.38746; logdet: 4.71370; lrLoss: 7.74449; logP: -7.45473; logdet: 4.71024; lrLoss: 7.74449; logP: -7.45473; logdet: 4.71024; lrLoss: 6.99601; logP: -6.70299; logdet: 4.70698; lrLoss: 6.99601; logP: -6.70299; logdet: 4.70698; lrLoss: 6.39183; logP: -6.09575; logdet: 4.70392; lrLoss: 6.39183; logP: -6.09575; logdet: 4.70392; lrLoss: 6.59313; logP: -6.29416; logdet: 4.70103; lrLoss: 6.59313; logP: -6.29416; logdet: 4.70103; lrLoss: 6.13956; logP: -5.83784; logdet: 4.69828; lrLoss: 6.13956; logP: -5.83784; logdet: 4.69828; lrLoss: 6.28449; logP: -5.98017; logdet: 4.69567; lrLoss: 6.28449; logP: -5.98017; logdet: 4.69567; lrLoss: 5.40901; logP: -5.10219; logdet: 4.69318; lrLoss: 5.40901; logP: -5.10219; logdet: 4.69318; lrLoss: 5.39622; logP: -5.08703; logdet: 4.69081; lrLoss: 5.39622; logP: -5.08703; logdet: 4.69081; lrLoss: 4.97754; logP: -4.66609; logdet: 4.68856; lrLoss: 4.97754; logP: -4.66609; logdet: 4.68856; lrLoss: 4.30392; logP: -3.99035; logdet: 4.68643; lrLoss: 4.30392; logP: -3.99035; logdet: 4.68643; lrLoss: 3.83837; logP: -3.52280; logdet: 4.68443; lrLoss: 3.83837; logP: -3.52280; logdet: 4.68443; lrLoss: 4.02862; logP: -3.71118; logdet: 4.68256; lrLoss: 4.02862; logP: -3.71118; logdet: 4.68256; lrLoss: 3.75658; logP: -3.43738; logdet: 4.68080; lrLoss: 3.75658; logP: -3.43738; logdet: 4.68080; lrLoss: 3.77961; logP: -3.45876; logdet: 4.67916; lrLoss: 3.77961; logP: -3.45876; logdet: 4.67916; lrLoss: 3.59959; logP: -3.27720; logdet: 4.67761; lrLoss: 3.59959; logP: -3.27720; logdet: 4.67761; lrLoss: 3.10592; logP: -2.78207; logdet: 4.67615; lrLoss: 3.10592; logP: -2.78207; logdet: 4.67615; lrLoss: 3.30807; logP: -2.98288; logdet: 4.67480; lrLoss: 3.30807; logP: -2.98288; logdet: 4.67480; lrLoss: 3.03063; logP: -2.70418; logdet: 4.67355; lrLoss: 3.03063; logP: -2.70418; logdet: 4.67355; lrLoss: 3.00233; logP: -2.67472; logdet: 4.67238; lrLoss: 3.00233; logP: -2.67472; logdet: 4.67238; lrLoss: 3.00889; logP: -2.68020; logdet: 4.67131; lrLoss: 3.00889; logP: -2.68020; logdet: 4.67131; lrLoss: 2.87956; logP: -2.54988; logdet: 4.67032; lrLoss: 2.87956; logP: -2.54988; logdet: 4.67032; lrLoss: 2.79350; logP: -2.46291; logdet: 4.66941; lrLoss: 2.79350; logP: -2.46291; logdet: 4.66941; lrLoss: 2.99124; logP: -2.65982; logdet: 4.66857; lrLoss: 2.99124; logP: -2.65982; logdet: 4.66857; lrLoss: 2.80066; logP: -2.46846; logdet: 4.66780; lrLoss: 2.80066; logP: -2.46846; logdet: 4.66780; lrLoss: 2.82990; logP: -2.49699; logdet: 4.66709; lrLoss: 2.82990; logP: -2.49699; logdet: 4.66709; lrLoss: 2.67329; logP: -2.33973; logdet: 4.66644; lrLoss: 2.67329; logP: -2.33973; logdet: 4.66644; lrLoss: 2.95796; logP: -2.62381; logdet: 4.66584; lrLoss: 2.95796; logP: -2.62381; logdet: 4.66584; lrLoss: 2.96202; logP: -2.62731; logdet: 4.66528; lrLoss: 2.96202; logP: -2.62731; logdet: 4.66528; lrLoss: 2.96272; logP: -2.62747; logdet: 4.66476; lrLoss: 2.96272; logP: -2.62747; logdet: 4.66476; lrLoss: 2.66700; logP: -2.33126; logdet: 4.66426; lrLoss: 2.66700; logP: -2.33126; logdet: 4.66426; lr